---
title: "Metodología de machine learning"
subtitle: "Aplicación en datos del bovino criollo colombiano Romosinuano"
author: "Jorge Leonardo López Martínez; Freddy Hernandez Barajas; Gustavo Alfonso Ossa Saraz"
institute: ""
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  xaringan::moon_reader:
    css: estilo.css
---

<!--- 
Alguito de información sobre el paquete xaringan (https://bookdown.org/yihui/rmarkdown/xaringan.html) 

1. Para realizar una presentación usando este paquete, se hace lo siguiente: File -> New File -> R Markdown -> From Template -> Ninja Presentation... aparecerá luego un ejemplo R markdown en el editor 

2. Atajos de teclado: luego de abrir las diapositivas generadas, se puede presionar la tecla h (help) o ? para acceder al atajo de teclado que ayudaran a presentar mejor sus diapositivas, como por ejemplo: 
  - Presione b para oscurecer una diapositiva, y m para invertir todo en la diapositiva. Estas técnicas pueden ser útiles cuando no desea que la audiencia lea la diapositiva, por ejemplo, cuando tiene soluciones en una diapositiva pero no quiere mostrarlas a sus alumnos de inmediato.
  - Presione f para alternar el modo de pantalla completa.
  - Presione p para alternar el modo de presentador, el cual mostrara miniaturas de la diapositiva actual y la siguiente diapositiva a la izquierda, notas del presentador a la derecha, y también un temporizador en la parte superior derecha. La tecla p pueden ser muy útil cuando se presenta con su propia computadora conectada a una segunda pantalla (como un proyector). Puede presionar t para reiniciar el temporizador en cualquier momento.

3. Notas del presentador: Puede escribir notas para leer en el modo de presentador. Estas notas están escritas bajo tres signos de interrogación (?) después de una diapositiva, y la sintaxis también es en Markdown, lo que significa que puede escribir cualquier elemento compatible con Markdown, como párrafos, listas, imágenes, etc
--->

```{r Paquetes a usar, echo = FALSE, eval = TRUE, message = FALSE}

library(demoR)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(rsample) # Este paquete se uso porque contiene funciones de interés como por ejemplo, funciones para dividir el conjunto de datos en datos de entrenamiento y de prueba.
library(tidymodels) # Este paquete consiste en una colección de paquetes para modelado y machine learning utilizando los principios del "tidyverse". Aquí https://www.tidymodels.org/find/ se encuentran todas las funciones disponibles en este paquete. Aquí https://www.tidymodels.org/help/ se pueden preparar preguntas para ayuda de tidymodels.
library(themis) # Este paquete contiene funciones para tratar con datos no balanceados.
library(raster)
library(sf)
library(ggsflabel)
library(ggforce)
library(patchwork)
library(moments)
library(kableExtra)
library(showtext) # Link donde estan las fuentes Google (http://www.google.com/fonts)
font_add_google('Gochi Hand', 'gochi')
showtext.auto()
```

<section style="text-align: center;"><h2><p class="text-info">Objetivo y población de estudio</p></h2></section>

<br>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Este estudio tuvo como objetivo aplicar la métodologia del <font color="black"><u>machine learning</u></font> en datos del bovino criollo colombiano Romosinuano.</p></section>

<section style="text-align: justify;"><p class="text-primary">Dichos datos se obtuvieron del núcleo animal de la raza criolla colombiana Romosinuano, el cual se mantiene como banco de germoplasma. Este núcleo se encuentra ubicado en el centro de investigación Turipaná (AGROSAVIA), localizado en el Valle del Sinú en el nordeste de Colombia.</p></section>

```{r Imagen, fig.align = 'center', eval = TRUE, echo = FALSE, message = FALSE, out.width = '280'}

knitr::include_graphics('Imagenes/Romo.jpg')
```

</div>

<div class = "col-md-6">

<!-- 
Con base en los tutoriales https://statnmap.com/2018-04-18-draw-maps-like-paintings/ y http://dlizcano.github.io/2018/05/23/Mapa-Animado-Fuegos.html se creo el mapa.
-->

```{r Mapa, fig.align = 'center', eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE, out.width = '520', fig.showtext = TRUE}

mapa_Col <- getData('GADM', country = 'COL', level = 1) # Se accede a la información de Colombia.
mapa_Col_sf <- st_as_sf(mapa_Col) # Se convierte el anterior a un objeto sf.

ggplot(data = mapa_Col_sf) +
  geom_sf(data = mapa_Col_sf, aes(fill = NAME_1, colour = NAME_1), alpha = 0.4, colour = NA) +
  #annotate(geom = 'text', x = -77, y = 9.6, label = 'Córdoba', family = 'gochi', size = 5.4, colour = 'black') +
  geom_sf_label_repel(aes(label = NAME_1), label.padding = unit(1, 'mm')) +
  scale_colour_manual(values = c('yellow', 'green', 'black', 'chartreuse', 'magenta', 'springgreen', 'green', 'gray54', 'yellow', 'green', 'black', 'chartreuse', 'magenta', 'springgreen', 'green', 'gray54', 'yellow', 'green', 'black', 'chartreuse', 'magenta', 'springgreen', 'green', 'gray54', 'yellow', 'green', 'black', 'chartreuse', 'magenta', 'springgreen', 'green', 'gray54')) +
  scale_fill_manual(values = c('yellow', 'green', 'black', 'chartreuse', 'magenta', 'springgreen', 'green', 'gray54', 'yellow', 'green', 'black', 'chartreuse', 'magenta', 'springgreen', 'green', 'gray54', 'yellow', 'green', 'black', 'chartreuse', 'magenta', 'springgreen', 'green', 'gray54', 'yellow', 'green', 'black', 'chartreuse', 'magenta', 'springgreen', 'green', 'gray54')) +
  scale_y_continuous(limits = c(-5.2, 12)) +
  scale_x_continuous(limits = c(-80, -65)) +
  theme_void() +
  theme(legend.position = 'none') +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

</div>

</div>

---

<section style="text-align: center;"><h2><p class="text-info">Los datos</p></h2></section>

<br>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">La base de datos comprende el registro informativo del carácter intervalo entre partos en el bovino criollo colombiano Romosinuano.</p></section>

<section style="text-align: justify;"><p class="text-primary">Dicha base de datos se caracteriza por presentar una <font color="black"><u>estructura de clúster de tipo longitudinal</u></font>, cuyo ejemplo se puede observar en la siguiente imagen:</p></section>

```{r Ejemplo estructura longitudinal, fig.align = 'center', eval = TRUE, echo = FALSE, message = FALSE, fig.showtext = TRUE, out.width = '280'}

data.frame(
  x = c(0.5, 1.5, 0.5, 2.6, 2.0), 
  y = c(1, 1.5, 2.3, 1.3, 2.5),
  grupo = c('A', 'B', 'C', 'D', 'E')
) %>%
  ggplot(aes(x0 = x, y0 = y, r = 0.5, fill = grupo, colour = grupo)) +
  geom_circle(alpha = 0.2, size = 1.0) +
  annotate(geom = 'text', x = 0.4, y = 1.2, label = 'IEP 1', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 0.6, y = 1.0, label = 'IEP 2', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 0.5, y = 0.8, label = 'IEP 3', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 1.1, y = 0.5, label = 'Bovino A', family = 'gochi', size = 10.4, colour = 'black') +
  annotate(geom = 'text', x = 1.4, y = 1.7, label = 'IEP 1', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 1.6, y = 1.5, label = '...', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 1.5, y = 1.3, label = 'IEP 5', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 1.6, y = 0.95, label = 'Bovino C', family = 'gochi', size = 10.4, colour = 'black') +
  annotate(geom = 'text', x = 0.4, y = 2.5, label = 'IEP 3', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 0.6, y = 2.3, label = 'IEP 4', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 0.5, y = 2.1, label = 'IEP 5', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 0.9, y = 2.84, label = 'Bovino B', family = 'gochi', size = 10.4, colour = 'black') +
  annotate(geom = 'text', x = 2.5, y = 1.5, label = 'IEP 1', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 2.7, y = 1.3, label = 'IEP 3', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 2.6, y = 1.1, label = 'IEP 6', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 2.7, y = 1.84, label = 'Bovino E', family = 'gochi', size = 10.4, colour = 'black') +
  annotate(geom = 'text', x = 1.9, y = 2.7, label = 'IEP 1', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 2.1, y = 2.5, label = 'IEP 2', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 2.0, y = 2.3, label = 'IEP 3', family = 'gochi', size = 8.4, colour = 'black') +
  annotate(geom = 'text', x = 2.5, y = 3.06, label = 'Bovino D', family = 'gochi', size = 10.4, colour = 'black') +
  theme_void() +
  theme(legend.position = 'none') +
  scale_fill_manual(values = c('black', 'cyan', 'red', 'yellow', 'green')) +
  scale_colour_manual(values = c('black', 'cyan', 'red', 'yellow', 'green')) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

<!--
La estructura longitudinal se da cuando la observación se mide múltiples veces dentro de un mismo grupo.
-->

</div>

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Por lo cual es necesario emplear el <font color="black"><u>modelo mixto</u></font> para tratar este tipo de datos, usando de forma simultanea la metodología del machine learning.</p></section>

```{r Imagen octocat, fig.align = 'center', out.width = "340", eval = TRUE, echo = FALSE, message = FALSE}

knitr::include_graphics('Imagenes/octocat.png')
```

</div>

</div>

---

<section style="text-align: center;"><h2><p class="text-info">Los datos</p></h2></section>

<br>

<section style="text-align: justify;"><p class="text-primary">Se inicio previamente con el <font color="black"><u>pre-procesamiento de los datos</u></font>, cuyo objetivo consistió en proporcionar un conjunto de datos de entrenamiento de buena calidad. <!-- El rendimiento del modelo tiene una relación lineal con la calidad de los datos de muestra de entrenamiento que se incorporaron al modelo mismo.--> Los pasos principales del pre-procesamiento de datos, a saber, fueron la extracción de los datos y su limpieza.</p></section>

<div class = "row">

<div class = "col-md-6">

<div class="alert alert-dismissible alert-warning">
  Extracción de los datos
</div>

</div>

<div class = "col-md-6">

</div>

</div>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">La <font color="black"><u>extracción de los datos</u></font> tiene un papel importante en mejorar el tiempo de aprendizaje y aumentar el tamaño de los datos. El objetivo de este proceso de extracción es adquirir la matriz de datos de entrada apropiada como muestra de aprendizaje.</p></section>

<section style="text-align: justify;"><p class="text-primary">La extracción de información en el conjunto de datos de este estudio se realizó mediante la selección de aquellas variables (predictoras) que tuvieran relación con la variable respuesta intervalo entre partos.</p></section>

</div>

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Esto debido a que el propósito de la metodología a emplear consiste en estimar el valor de dicha variable respuesta en base a las variables predictoras, como se puede observar en la expresión $\small y = f(x) + b$.</p></section>

<section style="text-align: justify;"><p class="text-primary">Las variables de estudio usadas en la modelación se presentan en la tabla a continuación:</p></section>

</div>

</div>

<!-- A continuación, se exporta la base de datos a usar y se seleccionan un conjunto de variables predictoras -->

```{r Exportación y selección de variables, echo = FALSE, eval = TRUE, message = FALSE}

Base_datos <- read.csv2(file = '/home/leo/Documentos/Ossa/a1120.csv', sep = ',', header = TRUE) # Este conjunto de datos ya fue depurado previamente (en Depuración.R esta todo este proceso)... dicha depruración consistió, por ejemplo, en rastrear bovinos con registros de un mismo parto repetidos, e incluir información de posibles partos faltantes.

Base_datos_2 <- Base_datos %>%
  mutate(
    Fech_parto = as.Date(as.character(Fech_parto, format = '%m/%d/%Y')),
    Mes_parto = format(Fech_parto, '%m'),
    Ano_parto = format(Fech_parto, '%Y')
  ) %>%
  dplyr::select(Hija, IEP, N_parto, Sexo_hija, Edad_parto, Mes_parto, Ano_parto, D_abierto)
```

---

<section style="text-align: center;"><h2><p class="text-info">Los datos</p></h2></section>

<br>

<section style="text-align: justify;"><p class="text-primary">Se inicio previamente con el <font color="black"><u>pre-procesamiento de los datos</u></font>, cuyo objetivo consistió en proporcionar un conjunto de datos de entrenamiento de buena calidad. <!-- El rendimiento del modelo tiene una relación lineal con la calidad de los datos de muestra de entrenamiento que se incorporaron al modelo mismo.--> Los pasos principales del pre-procesamiento de datos, a saber, fueron la extracción de los datos y su limpieza.</p></section>

<div class = "row">

<div class = "col-md-6">

<div class="alert alert-dismissible alert-warning">
  Extracción de los datos
</div>

</div>

<div class = "col-md-6">

</div>

</div>

<div class = "row">

<div class = "col-md-6">

<table class="table table-hover">
  <thead>
    <tr>
      <th scope="col">Nombre</th>
    </tr>
  </thead>
  <tbody>
    <tr class="table-danger">
      <th scope="row">Intervalo entre partos</th>
    </tr>
    <tr class="table-warning">
      <th scope="row">Orden de parto</th>
    </tr>
    <tr class="table-info">
      <th scope="row">Sexo de la cría</th>
    </tr>
    <tr class="table-dark">
      <th scope="row">Edad al parto</th>
    </tr>
    <tr class="table-light">
      <th scope="row">Mes de parto</th>
    </tr>
  </tbody>
</table>

</div>

<div class = "col-md-6">

<table class="table table-hover">
  <thead>
    <tr>
      <th scope="col">Nombre</th>
    </tr>
  </thead>
  <tbody>
    <tr class="table-secondary">
      <th scope="row">Año de parto</th>
    </tr>
    <tr class="table-danger">
      <th scope="row">Días abiertos</th>
    </tr>
  </tbody>
</table>

```{r, fig.align = 'center', out.width = '160', eval = TRUE, echo = FALSE, message = FALSE}

knitr::include_graphics('Imagenes/octocat_2.png')
```

</div>

</div>

---

<section style="text-align: center;"><h2><p class="text-info">Los datos</p></h2></section>

<br>

<section style="text-align: justify;"><p class="text-primary">Se inicio previamente con el <font color="black"><u>pre-procesamiento de los datos</u></font>, cuyo objetivo consistió en proporcionar un conjunto de datos de entrenamiento de buena calidad. <!-- El rendimiento del modelo tiene una relación lineal con la calidad de los datos de muestra de entrenamiento que se incorporaron al modelo mismo.--> Los pasos principales del pre-procesamiento de datos, a saber, fueron la extracción de los datos y su limpieza.</p></section>

<div class = "row">

<div class = "col-md-6">

<div class="alert alert-dismissible alert-warning">
  Limpieza de los datos
</div>

</div>

<div class = "col-md-6">

</div>

</div>

<div class = "row">

<div class = "col-md-6">

<!-- <section style="text-align: justify;"><p class="text-primary">La limpieza de los datos tiene el propósito de corregir los datos faltantes en los conjuntos de datos que provienen de varias fuentes, por ejemplo, error de datos de entrada, error de programación, error en la transferencia de datos, etc.</p></section> -->

<section style="text-align: justify;"><p class="text-primary">En el caso de datos de interés zootecnico, la limpieza consiste en no considerar animales con identificación dudosa, información fuera del rango normal de la variable respuesta o valores fisiológicamente anormales.</p></section>

<section style="text-align: justify;"><p class="text-primary">La limpieza de los datos en el conjunto de datos de este estudio consistió en limitar los días entre partos de 300 a 1278 días, los días abiertos de 21 a 250 días y no considerar datos faltantes (NA).</p></section>

</div>

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Luego los datos se transforman usando el método de codificación activa<!-- (Una codificación activa es un proceso que transforma características categóricas o discretas en una matriz numérica.)--> (conversión a variables dummy o variables indicadoras). Por ejemplo, el mes de parto se convirtió en una variable denominada época de parto (sequía, transición y lluvia). <!--La misma se convierte luego en una variable numerica (1, 2 y 3, respectivamente) para que la regresión de machine learning pueda comprenderla mejor. Es necesario convertir las características categóricas en una representación numérica. --></p></section>

<section style="text-align: justify;"><p class="text-primary">El resultado completo del pre-procesamiento de los datos se puede ver en la tabla a continuación:</p></section>

</div>

</div>

```{r Limpieza del conjunto de datos, echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}

Base_datos_3 <- Base_datos_2 %>%
  mutate(
    Sexo_hija = str_to_sentence(Sexo_hija), # Habian dos bovinos identificados como 'h' y 'm'... estos se cambiaron a 'H' y 'M'.
         Sexo_hija = str_trim(Sexo_hija) # Habia un bovino identificado como ' M'... este se cambio a 'M'.
    ) %>%
  filter(
    Sexo_hija %in% c('H', 'M') & # Habia un bovino identificado como "He:Rp"... este no se considero.
      IEP != 'is.na' & # No se consideraron valores faltantes para la variable respuesta intervalo entre partos.
      IEP >= 300 & IEP <= 1278 & # Se limitaron los días entre partos de 300 a 1278 días ya que valores fuera de este rango pueden no ser normales.
      D_abierto >= 21 & D_abierto <= 250 & # Los días abiertos fueron restringidos de 21 a 250 días, ya que valores fuera de éste rango pueden ser fisiológicamente anormales o estar registrados erróneamente.
      N_parto != 'is.na' & # No se consideraron valores faltantes para la variable predictora número de parto.
      Edad_parto != 'is.na' & # A continuación no se consideran valores incosistentes para la edad al parto:
      Edad_parto > 0 &
      Edad_parto != 20746
  ) %>%
  mutate(
    N_parto = as.factor(N_parto), 
    Mes_parto = as.integer(Mes_parto),
    Epoca_parto = case_when( # Fueron formadas tres clases definidas como meses de época de lluvia (meses de julio a septiembre), de transición (meses de abril a junio y de octubre a diciembre) y de sequía (meses de enero a marzo).
      Mes_parto %in% c(1:3) ~ 'Sequía',
      Mes_parto %in% c(4:6) ~ 'Transición',
      Mes_parto %in% c(7:9) ~ 'Lluvia',
      Mes_parto %in% c(10:12) ~ 'Transición'
      ),
    Sexo_hija = case_when(
      Sexo_hija == 'H' ~ 'Hembra',
      Sexo_hija == 'M' ~ 'Macho'
      )
    ) %>%
  mutate_if(is.character, as.factor) %>% # Aquí, se cambia las variables tipo caracter a factor.
  dplyr::select(Hija, IEP, N_parto, Sexo_hija, Edad_parto, Epoca_parto, Ano_parto, D_abierto) %>%
  rename('Individuo' = Hija, 'IEP' = IEP, 'OP' = N_parto, 'SC' = Sexo_hija, 'EdP' = Edad_parto, 'ÉpP' = Epoca_parto, 'AP' = Ano_parto, 'DA' = D_abierto)

write.table(Base_datos_3, file = 'Datos_Romo.csv', row.names = FALSE, col.names = TRUE, sep = ',', dec = '.') # Se importa lo anterior

#glimpse(Base_datos_3) # Esta función es similar a la función str().

edad_parto <- Base_datos_2 %>%
  mutate(N_parto = as.factor(N_parto)) %>%
  filter(
    Edad_parto != 'is.na' &
      Edad_parto > 0
    ) %>%
  group_by(N_parto) %>%
  summarise(Promedio = mean(Edad_parto), N = length(N_parto), Mínimo = min(Edad_parto), Máximo = max(Edad_parto))
```

---

<section style="text-align: center;"><h2><p class="text-info">Los datos</p></h2></section>

<br>

```{r eval = require('DT'), tidy = FALSE, echo = FALSE, eval = TRUE, message = FALSE}

DT::datatable(
  head(Base_datos_3, 7395), 
  fillContainer = FALSE, options = list(pageLength = 5),
  caption = htmltools::tags$caption(
    style = 'caption-side: bottom; text-align: left;',
    htmltools::em('IEP = Intervalo entre partos, OP = Orden de parto, SC = Sexo de la cría, EdP = Edad al parto, ÉpP = Época de parto, AP = Año de parto, DA = Días abiertos.')
    )
  )
```

---

<section style="text-align: center;"><h2><p class="text-info">División de los datos en train y test</p></h2></section>

<br>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">En estadística se suele dividir los datos en dos subconjuntos: datos de <font color="black"><u>entrenamiento</u></font> y datos de <font color="black"><u>prueba</u></font> (y a veces en tres: entrenamiento, <font color="black"><u>validación</u></font> y prueba):</p></section>

```{r Divisón de los datos en train y test 1, fig.align = 'center', eval = TRUE, echo = FALSE, message = FALSE, fig.showtext = TRUE, out.width = '280'}

data.frame(
  x = c(1:4), y =c(1:4)
) %>%
  ggplot(aes(x, y)) +
  geom_blank() +
  annotate(geom = 'rect', xmin = 1.4, xmax = 3.6, ymin = 3.5, ymax = 4.0, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'text', x = 2.5, y = 3.75, label = 'Datos originales', family = 'gochi', size = 9.2, colour = 'black') +
  annotate(geom = 'rect', xmin = 1.4, xmax = 2.77, ymin = 2.9, ymax = 3.4, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.8, xmax = 3.6, ymin = 2.9, ymax = 3.4, colour = 'red', fill = 'red', alpha = 0.4, size = 1.2) +
  annotate(geom = 'text', x = 2.1, y = 3.15, label = 'Entrenamiento', family = 'gochi', size = 8.0, colour = 'black') +
  annotate(geom = 'text', x = 3.2, y = 3.15, label = 'Prueba', family = 'gochi', size = 9.2, colour = 'black') +
  annotate(geom = 'segment', x = 1.4, xend = 2.8, y = 2.78, yend = 2.78, colour = 'black', size = 2.0) +
  annotate(geom = 'text', x = 2.1, y = 2.6, label = 'Método de remuestreo', family = 'gochi', size = 8.8, colour = 'black') +
  annotate(geom = 'segment', x = 2.1, xend = 2.1, y = 2.78, yend = 2.68, colour = 'black', size = 2.0) +
  annotate(geom = 'rect', xmin = 1.4, xmax = 1.6, ymin = 1.9, ymax = 2.4, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 1.6, xmax = 1.8, ymin = 1.9, ymax = 2.4, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 1.8, xmax = 2.0, ymin = 1.9, ymax = 2.4, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.0, xmax = 2.2, ymin = 1.9, ymax = 2.4, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.2, xmax = 2.4, ymin = 1.9, ymax = 2.4, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.4, xmax = 2.6, ymin = 1.9, ymax = 2.4, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.6, xmax = 2.8, ymin = 1.9, ymax = 2.4, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  geom_curve(x = 2.84, xend = 3.2, y = 2.15, yend = 2.8, arrow = arrow(length = unit(0.1, 'inch')), size = 2.0, color = 'black', curvature = +0.4) +
  annotate(geom = 'text', x = 2.14, y = 1.68, label = 'Si los datos lo permiten:', family = 'gochi', size = 8.8, colour = 'black') +
  annotate(geom = 'rect', xmin = 1.4, xmax = 2.25, ymin = 1.0, ymax = 1.5, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.28, xmax = 2.78, ymin = 1.0, ymax = 1.5, colour = 'cyan', fill = 'cyan', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.8, xmax = 3.6, ymin = 1.0, ymax = 1.5, colour = 'red', fill = 'red', alpha = 0.4, size = 1.2) +
  annotate(geom = 'text', x = 1.8, y = 1.35, label = 'Entrena-', family = 'gochi', size = 8.2, colour = 'black') +
  annotate(geom = 'text', x = 1.8, y = 1.15, label = 'miento', family = 'gochi', size = 8.2, colour = 'black') +
  annotate(geom = 'text', x = 2.52, y = 1.35, label = 'Valida-', family = 'gochi', size = 8.0, colour = 'black') +
  annotate(geom = 'text', x = 2.52, y = 1.15, label = 'ción', family = 'gochi', size = 8.0, colour = 'black') +
  annotate(geom = 'text', x = 3.2, y = 1.25, label = 'Prueba', family = 'gochi', size = 9.2, colour = 'black') +
  theme_void() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

<section style="text-align: justify;"><p class="text-primary">El modelo de regresión se ajusta y se hacen predicciones con los datos de entrenamiento, y los datos de prueba se usan para medir el rendimiento del modelo. En este estudio:</p></section>

</div>

<div class = "col-md-6">

<!--
Hay información del proceso de dividir los datos en train y test en:
- Split into train/test en http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/.
-->

<!--
La función initial_split() toma los datos originales y guarda en un objeto la información sobre cómo hacer la división de los datos. Este es el enfoque más común de dividir los datos: una cuarta parte de los datos se reservan para el conjunto de prueba... así mediante muestreo aleatorio se selecciona al azar el 25% de los datos en datos de prueba y el resto (75%) para el conjunto de entrenamiento.
-->

```{r Division de los datos en train y test 2, echo = FALSE, eval = TRUE, message = FALSE}

set.seed(1234)
demo_code('
division_datos <- initial_split(data = Base_datos_3, prop = 3/4)
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE)
```

<!--
La salida impresa de division_datos a continuación, dice cuantas observaciones se tienen en el conjunto de entrenamiento, en el conjunto de pruebas, y cuando suman en total.
-->

```{r, echo = FALSE, eval = FALSE, message = FALSE}

division_datos
```

<!--
NOTA: Dado que el muestreo aleatorio anterior usa números aleatorios, es importante establecer la semilla (mediante la función set.seed()) del número aleatorio. Esto garantiza que los números aleatorios se puedan reproducir más adelante (si es necesario).¿¿¿¿Preguntar después al profe Freddy si es necesario establecer una semilla en el trabajo????
-->

<!--
Los datos de entrenamiento se usan para ajustar el modelo, estimar parámetros, comparar modelos, etc.
-->

```{r Division de los datos en train y test 3, echo = FALSE, eval = TRUE, message = FALSE}

demo_code('
datos_entrenamiento <- training(division_datos)
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE)
```

<!--
Los datos de prueba se usan como una fuente imparcial para medir el rendimiento del modelo final. Estos se mantienen en reserva hasta el final del proyecto, momento en el que solo debe haber uno o dos modelos bajo consideración seria.
-->

```{r División de los datos en train y test 4, echo = FALSE, eval = TRUE, message = FALSE}

demo_code('
datos_prueba <- testing(division_datos)
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE)
```

<section style="text-align: justify;"><p class="text-primary">Muchas veces además de dividir el conjunto de datos en entrenamiento y prueba, se suele elegir aleatoriamente X% (por ejemplo un 80%) del conjunto de datos de entrenamiento para que sea el conjunto de entrenamiento real y el % restante (100-X) para que sea el conjunto de validación. El modelo se entrena iterativamente y se valida en estos conjuntos de datos diferentes. Esto se conoce comúnmente como <font color="black"><u>método de remuestreo</u></font>. <!--Básicamente, usa el conjunto de entrenamiento para generar múltiples divisiones de los conjuntos de entrenamiento y validación. La validación cruzada evita el ajuste excesivo y se está volviendo cada vez más popular, siendo la validación cruzada K-fold el método más popular de validación cruzada.--></p></section>

</div>

</div>

---

<section style="text-align: center;"><h2><p class="text-info">División de los datos en train y test</p></h2></section>

<br>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Los métodos de remuestreo, como la <font color="black"><u>validación cruzada</u></font> y el <font color="black"><u>bootstrap</u></font>, son sistemas de simulación empírica. Crean una serie de conjuntos de datos similares a la división de entrenamiento y prueba discutida con anterioridad: se usa un subconjunto de datos para crear el modelo y se utiliza un subconjunto diferente para medir el rendimiento. El remuestreo siempre se usa con el conjunto de entrenamiento:</p></section>

```{r Divisón de los datos en train y test 5, fig.align = 'center', eval = TRUE, echo = FALSE, message = FALSE, fig.showtext = TRUE, out.width = '300'}

data.frame(
  x = c(0.25:4.25), y = c(0.0:4.0)
) %>%
  ggplot(aes(x, y)) +
  geom_blank() +
  theme_void() +
  annotate(geom = 'rect', xmin = 1.4, xmax = 3.6, ymin = 3.5, ymax = 4.0, colour = 'black', fill = 'white', alpha = 0.4, size = 1.2) +
  annotate(geom = 'text', x = 2.5, y = 3.75, label = 'Datos originales', family = 'gochi', size = 7.8, colour = 'black') +
  annotate(geom = 'rect', xmin = 1.4, xmax = 2.77, ymin = 2.5, ymax = 3.0, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.8, xmax = 3.6, ymin = 2.5, ymax = 3.0, colour = 'red', fill = 'red', alpha = 0.4, size = 1.2) +
  #annotate(geom = 'text', x = 2.1, y = 2.75, label = 'Entrenamiento', family = 'gochi', size = 6.6, colour = 'black') +
  #annotate(geom = 'text', x = 3.2, y = 2.75, label = 'Prueba', family = 'gochi', size = 7.8, colour = 'black') +
  geom_curve(x = 2.45, xend = 2.1, y = 3.4, yend = 3.1, arrow = arrow(length = unit(0.1, 'inch')), size = 1.4, color = 'black', curvature = 0.0) +
  geom_curve(x = 2.55, xend = 3.2, y = 3.4, yend = 3.1, arrow = arrow(length = unit(0.1, 'inch')), size = 1.4, color = 'black', curvature = 0.0) +
  geom_curve(x = 2.0, xend = 1.4, y = 2.4, yend = 2.0, arrow = arrow(length = unit(0.1, 'inch')), size = 1.4, color = 'black', curvature = 0.0) +
  geom_curve(x = 2.1, xend = 2.1, y = 2.4, yend = 2.0, arrow = arrow(length = unit(0.1, 'inch')), size = 1.4, color = 'black', curvature = 0.0) +
  geom_curve(x = 2.2, xend = 2.8, y = 2.4, yend = 2.0, arrow = arrow(length = unit(0.1, 'inch')), size = 1.4, color = 'black', curvature = 0.0) +
  annotate(geom = 'text', x = 0.8, y = 1.9, label = 'Remuestreo 1', family = 'gochi', size = 6.6, colour = 'black') +
  annotate(geom = 'text', x = 2.1, y = 1.9, label = 'Remuestreo 2', family = 'gochi', size = 6.6, colour = 'black') +
  annotate(geom = 'text', x = 3.4, y = 1.9, label = 'Remuestreo B', family = 'gochi', size = 6.6, colour = 'black') +
  geom_curve(x = 0.8, xend = 0.8, y = 1.7, yend = 1.4, arrow = arrow(length = unit(0.1, 'inch')), size = 1.4, color = 'black', curvature = 0.0) +
  geom_curve(x = 2.1, xend = 2.1, y = 1.7, yend = 1.4, arrow = arrow(length = unit(0.1, 'inch')), size = 1.4, color = 'black', curvature = 0.0) +
  geom_curve(x = 3.4, xend = 3.4, y = 1.7, yend = 1.4, arrow = arrow(length = unit(0.1, 'inch')), size = 1.4, color = 'black', curvature = 0.0) +
  annotate(geom = 'rect', xmin = 0.25, xmax = 1.0, ymin = 0.8, ymax = 1.3, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 1.03, xmax = 1.3, ymin = 0.8, ymax = 1.3, colour = 'cyan', fill = 'cyan', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 1.5, xmax = 2.25, ymin = 0.8, ymax = 1.3, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.28, xmax = 2.5, ymin = 0.8, ymax = 1.3, colour = 'cyan', fill = 'cyan', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.7, xmax = 3.45, ymin = 0.8, ymax = 1.3, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 3.48, xmax = 3.74, ymin = 0.8, ymax = 1.3, colour = 'cyan', fill = 'cyan', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 0.25, xmax = 0.5, ymin = 3.25, ymax = 3.5, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'text', x = 0.95, y = 3.4, label = 'Entrena-', family = 'gochi', size = 5.8, colour = 'black') +
  annotate(geom = 'text', x = 0.95, y = 3.2, label = 'miento', family = 'gochi', size = 5.8, colour = 'black') +
  annotate(geom = 'rect', xmin = 0.25, xmax = 0.5, ymin = 2.75, ymax = 3.0, colour = 'red', fill = 'red', alpha = 0.4, size = 1.2) +
  annotate(geom = 'text', x = 0.90, y = 2.8, label = 'Prueba', family = 'gochi', size = 5.8, colour = 'black') +
  annotate(geom = 'rect', xmin = 0.25, xmax = 0.5, ymin = 2.25, ymax = 2.5, colour = 'cyan', fill = 'cyan', alpha = 0.4, size = 1.2) +
  annotate(geom = 'text', x = 0.88, y = 2.4, label = 'Valida-', family = 'gochi', size = 5.8, colour = 'black') +
  annotate(geom = 'text', x = 0.84, y = 2.2, label = 'ción', family = 'gochi', size = 5.8, colour = 'black') +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

</div>

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">En el primer nivel del diagrama anterior, se emplea la función <font color="black">rsample::initial_split( )</font>, que divide los datos originales en conjuntos de entrenamiento y de prueba (como se hizo anteriormente). Luego, se eligen los datos de entrenamiento para volver a muestrear y se mantiene los datos del subconjunto de prueba.</p></section>

<section style="text-align: justify;"><p class="text-primary">Para generar estos nuevos datos en el estudio:</p></section>

<!--
Para generar estos resultados, el primer paso es crear un objeto de remuestreo usando el paquete "rsample". Hay varios métodos de remuestreo implementados en rsample. Se uso la función validation_split():
-->

```{r División de los datos en train y test 6, echo = FALSE, eval = TRUE, message = FALSE}

demo_code('
datos_val <- validation_split(datos_entrenamiento, prop = 0.80)
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE)
```

<!--
Se usó la función validation_split() para asignar el 20% de los datos del conjunto de entrenamiento a un nuevo conjunto llamado de validación, y el 80% restante a un nuevo conjunto de entrenamiento. En tidymodels, un conjunto de validación se trata como una única iteración de remuestreo. Esto significa que nuestras métricas de rendimiento del modelo se calcularán en un solo conjunto de aproximadamente 1109 (5546*0.20) intervalos entre partos.

Otra forma sería usar mútiples iteraciones de remuestreo (que se haria por medio de la función vfold_cv() por ejemplo con k = 10 para crear 10 muestras diferentes del conjunto de entrenamiento el cual se divide en entrenamiento y prueba, y producir 10 métricas de rendimiento diferentes (vfold_cv(datos_entrenamiento, k = 10))).

Este último método asignaria de forma aleatoria las 5546 observaciones (que hacen parte del conjunto de entrenamiento) a 10 muestras diferentes de aproximadamente el mismo tamaño, llamados "pliegues" ("fold" en ingles), produciendo 10 métrica de rendimiento diferentes. Para la primera iteración de remuestreo, el primer pliegue de aproximadamente 555 observaciones (el 10% de las 5546 observaciones) se usa con el fin de medir el rendimiento del modelo (esto es similar a un conjunto de prueba, y para evitar confusiones con este último se denomina como evaluación o validación). El otro 90% de los datos (aproximadamente 4491 observaciones) se utilizan para ajustar el modelo. Nuevamente, esto suena similar a un conjunto de entrenamiento, por lo que en tidymodels se suele llamar a estos datos el conjunto de análisis. Este modelo, entrenado en el conjunto de análisis, se aplica al conjunto de evaluación para generar predicciones, y las estadísticas de rendimiento se calculan en función de esas predicciones.

En este estudio, el CV 10 veces se mueve iterativamente a través de los pliegues y deja un 10% diferente cada vez para la evaluación del modelo. Al final de este proceso, hay 10 conjuntos de estadísticas de rendimiento que se crearon en 10 conjuntos de datos que no se utilizaron en el proceso de modelado. Esto significa 10 precisiones y 10 áreas bajo la curva ROC (una de las metricas usadas para evaluar el rendimiento). Si bien se crearon 10 modelos, estos no se usan más; no se mantienena los modelos mismos entrenados en estos pliegues porque su único propósito es calcular las métricas de rendimiento. Las estimaciones finales de muestreo para el modelo serían los promedios de las de estadísticas de rendimiento de las réplicas.
-->

```{r, echo = FALSE, eval = FALSE, message = FALSE}

datos_vc
```

<!--
Al visualizar lo anterior se observa que la columna de la lista denominada "splits" contiene la información sobre las filas que pertenecen a los conjuntos de análisis (o entrenamiento) y validación (o evaluación). Hay funciones que se pueden usar para extraer los datos remuestreados individuales llamados analysis() y assessment().
-->

<section style="text-align: justify;"><p class="text-primary"><!-- La validación cruzada es un paso esencial en el proceso de entrenamiento de modelos basados en datos. -->Su proposito consiste en estimar el rendimiento final del modelo a partir de estadísticas de rendimiento (como la precisión y el ROC) al igual que hace con los datos de prueba<!-- y reducir el sobreajuste al particionar conjuntos de datos en k-fold. El remuestreo permite simular qué tan bien se desempeñará el modelo con los nuevos datos, y el conjunto de prueba actúa como la verificación final e imparcial del rendimiento del modelo -->.</p></section>

</div>

</div>

---

<section style="text-align: center;"><h2><p class="text-info">Transformación de las variables</p></h2></section>

<br>

<section style="text-align: justify;"><p class="text-primary">Existen varios métodos para <font color="black"><u>normalizar</u></font> las variables. La elección de dicho método depende de la distribución de los datos y la presencia de valores atípicos en los datos.</p></section>

<div class = "row">

<div class = "col-md-6">

<div class="alert alert-dismissible alert-warning">
  Valores atípicos
</div>

</div>

<div class = "col-md-6">

</div>

</div>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Un valor atípico es una observación cuyo valor de la variable respuesta es condicionalmente inusual dado el valor de la variable predictora.</p></section>

<section style="text-align: justify;"><p class="text-primary">Estos son problemáticos porque pueden afectar el rendimiento predictivo de los algoritmos de machine learning, y porque su presencia puede ser una señal de que el modelo no logra capturar características importantes de los datos.</p></section>

<section style="text-align: justify;"><p class="text-primary">El <font color="black"><u>boxplot</u></font> es un método <!--típicamente representado por cuartiles e intercuartiles--> que ayuda a definir el límite superior e inferior más allá de los cuales cualquier dato que se encuentre es considerado como atípico. <!--El propósito mismo de este diagrama es identificar valores atípicos y descartarlos de la serie de datos antes de hacer cualquier observación adicional para que la conclusión del estudio proporcione resultados más precisos no influenciados por ningún extremo o valores anormales.--></p></section>

</div>

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Según los estándares básicos seguidos por los estadísticos, una definición conveniente de un valor atípico es un punto que cae más de 1.5 veces el rango intercuartil (IQR) por encima del tercer cuartil (Q3) o por debajo del primer cuartil (Q1):</p></section>

```{r Ejemplo de diagrama de caja y bigotes, fig.align = 'center', eval = FALSE, echo = FALSE, message = FALSE, fig.showtext = TRUE, out.width = '100%'}

Val_atipicos <- data.frame(
  x = c(1.1, 1.14, 3.9, 3.95, 3.84), y = c(2.5, 2.5, 2.5, 2.5, 2.5)
)

data.frame(
  x = c(1:4), y =c(1:4)
) %>%
  ggplot(aes(x, y)) +
  geom_blank() +
  annotate(geom = 'rect', xmin = 1.8, xmax = 3.2, ymin = 2.4, ymax = 2.6, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'segment', x = 2.4, xend = 2.4, y = 2.4, yend = 2.6, colour = 'yellow', size = 1.2) +
  annotate(geom = 'segment', x = 1.8, xend = 1.2, y = 2.5, yend = 2.5, colour = 'yellow', size = 1.2) +
  annotate(geom = 'segment', x = 3.2, xend = 3.8, y = 2.5, yend = 2.5, colour = 'yellow', size = 1.2) +
  annotate(geom = 'text', x = 2.5, y = 2.0, label = 'IQR', family = 'gochi', size = 34.0, colour = 'black') +
  geom_curve(x = 2.3, xend = 1.8, y = 2.0, yend = 2.0, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  geom_curve(x = 2.7, xend = 3.2, y = 2.0, yend = 2.0, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  annotate(geom = 'text', x = 1.5, y = 2.0, label = '1.5 IQR', family = 'gochi', size = 24.0, colour = 'black') +
  geom_curve(x = 1.72, xend = 1.8, y = 2.0, yend = 2.0, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  geom_curve(x = 1.28, xend = 1.2, y = 2.0, yend = 2.0, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  annotate(geom = 'text', x = 3.5, y = 2.0, label = '1.5 IQR', family = 'gochi', size = 24.0, colour = 'black') +
  geom_curve(x = 3.28, xend = 3.2, y = 2.0, yend = 2.0, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  geom_curve(x = 3.72, xend = 3.8, y = 2.0, yend = 2.0, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  annotate(geom = 'segment', x = 1.8, xend = 1.8, y = 2.2, yend = 1.8, colour = 'black', size = 1.2) +
  annotate(geom = 'segment', x = 3.2, xend = 3.2, y = 2.2, yend = 1.8, colour = 'black', size = 1.2) +
  annotate(geom = 'segment', x = 1.2, xend = 1.2, y = 2.8, yend = 1.8, colour = 'black', size = 1.2) +
  annotate(geom = 'segment', x = 3.8, xend = 3.8, y = 2.8, yend = 1.8, colour = 'black', size = 1.2) +
  annotate(geom = 'text', x = 1.2, y = 1.7, label = 'Límite', family = 'gochi', size = 30.0, colour = 'black') +
  annotate(geom = 'text', x = 1.2, y = 1.5, label = 'inferior', family = 'gochi', size = 30.0, colour = 'black') +
  annotate(geom = 'text', x = 3.8, y = 1.7, label = 'Límite', family = 'gochi', size = 30.0, colour = 'black') +
  annotate(geom = 'text', x = 3.8, y = 1.5, label = 'superior', family = 'gochi', size = 30.0, colour = 'black') +
  annotate(geom = 'text', x = 1.6, y = 3.0, label = 'Q1', family = 'gochi', size = 32.0, colour = 'black') +
  annotate(geom = 'text', x = 2.5, y = 3.0, label = 'Q2', family = 'gochi', size = 32.0, colour = 'black') +
  annotate(geom = 'text', x = 3.4, y = 3.0, label = 'Q3', family = 'gochi', size = 32.0, colour = 'black') +
  geom_curve(x = 1.6, xend = 1.8, y = 2.9, yend = 2.65, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  geom_curve(x = 3.4, xend = 3.2, y = 2.9, yend = 2.65, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  geom_curve(x = 2.5, xend = 2.5, y = 2.9, yend = 2.65, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  geom_point(data = Val_atipicos, aes(x = x, y = y), colour = 'gray54', alpha = 0.4, size = 4.4) +
  geom_curve(x = 1.14, xend = 1.1, y = 2.9, yend = 2.65, arrow = arrow(length = unit(0.1, 'inch')), size = 0.8, color = 'black', curvature = 0.0) +
  annotate(geom = 'text', x = 1.1, y = 3.2, label = 'Valor', family = 'gochi', size = 30.0, colour = 'black') +
  annotate(geom = 'text', x = 1.1, y = 3.0, label = 'atípico', family = 'gochi', size = 30.0, colour = 'black') +
  theme_void() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  ggsave(filename = '/home/leo/Escritorio/github/Mi_practica/ML_DL/Diapositivas/Imagenes/boxplot.png')
```

```{r Imagen boxplot, fig.align = 'center', out.width = "320", eval = TRUE, echo = FALSE, message = FALSE}

knitr::include_graphics('Imagenes/boxplot.png')
```

<!--
Se observó que el número de valores atípicos en el conjunto de datos es bastante alto.
-->

</div>

</div>

---

<section style="text-align: center;"><h2><p class="text-info">Transformación de las variables</p></h2></section>

```{r Diagrama de caja y bigotes para identificar valores atípicos, echo = FALSE, eval = TRUE, message = FALSE, fig.align = 'center', out.width = '570'}

is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
  } # Los valores atípicos son aquellas observaciones que se encuentran 1.5 veces IQR, donde IQR (el rango intercuartil) es la diferencia entre lo cuartiles 75 y 25... esta función permite identificar dentro del conjunto de datos aquellos valores atípicos

boxplot_OP_DE <- datos_entrenamiento %>%
  dplyr::select(IEP, OP) %>%
  #mutate(Val_atipico = ifelse(is_outlier(IEP), IEP, as.numeric(NA))) %>%
  ggplot(aes(x = OP, y = IEP, colour = OP, fill = OP)) +
  #geom_jitter(colour = 'gray38', alpha = 0.4, size = 2.0, position = position_jitter(width = 0.1, height = 0.1)) +
  geom_boxplot(alpha = 0.4, outlier.colour = 'gray14', outlier.fill = 'gray14', outlier.size = 2.4) +
  stat_summary(fun = 'mean', geom = 'point', shape = '*', size = 5.8, color = 'black', fill = 'black') +
  #geom_text(aes(label = Val_atipico), na.rm = TRUE, hjust = -0.4, colour = 'gray54') +
  scale_colour_manual(values = c('yellow', 'turquoise1', 'violetred1', 'chartreuse', 'magenta', 'springgreen', 'green', 'black', 'yellow', 'turquoise1', 'violetred1', 'chartreuse', 'magenta', 'springgreen', 'green', 'black')) +
  scale_fill_manual(values = c('yellow', 'turquoise1', 'violetred1', 'chartreuse', 'magenta', 'springgreen', 'green', 'black', 'yellow', 'turquoise1', 'violetred1', 'chartreuse', 'magenta', 'springgreen', 'green', 'black')) +
  theme_bw() +
  labs(x = 'Orden de parto', y = 'Intervalo entre partos', title = 'Datos de entrenamiento') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 10, face = 'bold'),
        axis.title = element_text(size = 12, face = 'bold'),
        plot.title = element_text(size = 12, face = 'bold'))

boxplot_OP_DP <- datos_prueba %>%
  dplyr::select(IEP, OP) %>%
  #mutate(Val_atipico = ifelse(is_outlier(IEP), IEP, as.numeric(NA))) %>%
  ggplot(aes(x = OP, y = IEP, colour = OP, fill = OP)) +
  #geom_jitter(colour = 'gray38', alpha = 0.4, size = 2.0, position = position_jitter(width = 0.1, height = 0.1)) +
  geom_boxplot(alpha = 0.4, outlier.colour = 'gray14', outlier.fill = 'gray14', outlier.size = 2.4) +
  stat_summary(fun = 'mean', geom = 'point', shape = '*', size = 5.8, color = 'black', fill = 'black') +
  #geom_text(aes(label = Val_atipico), na.rm = TRUE, hjust = -0.4, colour = 'gray54') +
  scale_colour_manual(values = c('yellow', 'turquoise1', 'violetred1', 'chartreuse', 'magenta', 'springgreen', 'green', 'black', 'yellow', 'turquoise1', 'violetred1', 'chartreuse', 'magenta', 'springgreen', 'green', 'black')) +
  scale_fill_manual(values = c('yellow', 'turquoise1', 'violetred1', 'chartreuse', 'magenta', 'springgreen', 'green', 'black', 'yellow', 'turquoise1', 'violetred1', 'chartreuse', 'magenta', 'springgreen', 'green', 'black')) +
  theme_bw() +
  labs(x = 'Orden de parto', y = 'Intervalo entre partos', title = 'Datos de prueba') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 10, face = 'bold'),
        axis.title = element_text(size = 12, face = 'bold'),
        plot.title = element_text(size = 12, face = 'bold'))

boxplot_SC <- Base_datos_3 %>%
  dplyr::select(IEP, SC) %>%
  mutate(Val_atipico = ifelse(is_outlier(IEP), IEP, as.numeric(NA))) %>%
  ggplot(aes(x = SC, y = IEP, colour = SC, fill = SC)) +
  #geom_jitter(colour = 'gray38', alpha = 0.4, size = 2.0, position = position_jitter(width = 0.1, height = 0.1)) +
  geom_boxplot(alpha = 0.4, outlier.colour = 'gray14', outlier.fill = 'gray14', outlier.size = 2.4) +
  stat_summary(fun = 'mean', geom = 'point', shape = '*', size = 5.8, color = 'black', fill = 'black') +
  #geom_text(aes(label = Val_atipico), na.rm = TRUE, hjust = -0.4, colour = 'gray54') +
  scale_colour_manual(values = c('yellow', 'turquoise1')) +
  scale_fill_manual(values = c('yellow', 'turquoise1')) +
  theme_bw() +
  labs(x = 'Sexo de la cría', y = 'Intervalo entre partos') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 10, face = 'bold'),
        axis.title = element_text(size = 12, face = 'bold'))

boxplot_EpP <- Base_datos_3 %>%
  dplyr::select(IEP, ÉpP) %>%
  mutate(Val_atipico = ifelse(is_outlier(IEP), IEP, as.numeric(NA))) %>%
  ggplot(aes(x = ÉpP, y = IEP, colour = ÉpP, fill = ÉpP)) +
  #geom_jitter(colour = 'gray38', alpha = 0.4, size = 2.0, position = position_jitter(width = 0.1, height = 0.1)) +
  geom_boxplot(alpha = 0.4, outlier.colour = 'gray14', outlier.fill = 'gray14', outlier.size = 2.4) +
  stat_summary(fun = 'mean', geom = 'point', shape = '*', size = 5.8, color = 'black', fill = 'black') +
  #geom_text(aes(label = Val_atipico), na.rm = TRUE, hjust = -0.4, colour = 'gray54') +
  scale_colour_manual(values = c('violetred1', 'green', 'black')) +
  scale_fill_manual(values = c('violetred1', 'green', 'black')) +
  theme_bw() +
  labs(x = 'Época de parto', y = 'Intervalo entre partos') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 10, face = 'bold'),
        axis.title = element_text(size = 12, face = 'bold'))

(boxplot_OP_DE) / (boxplot_OP_DP)
```

---

<section style="text-align: center;"><h2><p class="text-info">Transformación de las variables</p></h2></section>

<br>

<section style="text-align: justify;"><p class="text-primary">Existen varios métodos para <font color="black"><u>normalizar</u></font> las variables. La elección de dicho método depende de la distribución de los datos y la presencia de valores atípicos en los datos.</p></section>

<div class = "row">

<div class = "col-md-6">

<div class="alert alert-dismissible alert-warning">
  Distribución de de los datos
</div>

</div>

<div class = "col-md-6">

</div>

</div>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">La distribución de probabilidad, se refiere a todos los resultados posibles de una variable aleatoria (discreta o continua). Es decir, describe el comportamiento de dicha variable dentro de un intervalo de valores o de posibles resultados.<!-- Las distribuciones revelan información útil, pero la información es probabilística.--></p></section>

<!-- La distribución de probabilidad permite asignar a cada evento la probabilidad de que este ocurra o tenga éxito. Con el estudio de las probabilidades, se ha permitido una manera de estandarizar los sucesos y procesos que ocurren al azar, esto se ha logrado estimando las frecuencias en las que se obtiene un resultado en específico. -->

<!-- Aquí (https://www.tidymodels.org/learn/models/parsnip-nnet/) muestran que este proceso de ver la distribución de los datos se realiza usando los datos de entrenamiento. -->

```{r Ejemplo de distribución normal de los datos, fig.align = 'center', eval = TRUE, echo = FALSE, message = FALSE, fig.showtext = TRUE, out.width = '220'}

Normal <- function(n, Lower, Upper) { # Función para simular datos con distribución normal
  set.seed (100)
  x = rnorm(n, 0, 1)
  data.frame(x)
  }

Normal(200) %>%
  ggplot(aes(x = x)) +
  geom_histogram(aes(y = ..density..), bins = 28, fill = 'yellow', colour = 'yellow', alpha = 0.4) +
  geom_density(size = 2.2, colour = 'black') +
  #annotate(geom = 'text', x = 1.5, y = 0.5, label = 'Distribución normal', family = 'gochi', size = 8.8, colour = 'black') +
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

</div>

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">La forma más fácil de entender una distribución es visualizarla. Un <font color="black"><u>histograma</u></font> como el de la imagen es un ejemplo de dicha visualización.</p></section>

<section style="text-align: justify;"><p class="text-primary">De igual forma, las propiedades de una distribución se pueden describir mediante la <font color="black"><u>estadística descriptiva</u></font> como:</p></section>

<div class="form-check">
  <div class="form-check disabled">
    <input class="form-check-input" type="checkbox" value="" disabled="">
    La media;
  </div>
  <div class="form-check disabled">
    <input class="form-check-input" type="checkbox" value="" disabled="">
    La mediana;
  </div>
  <div class="form-check disabled">
    <input class="form-check-input" type="checkbox" value="" disabled="">
    El sesgo;
  </div>
  <div class="form-check disabled">
    <input class="form-check-input" type="checkbox" value="" disabled="">
    La curtosis.
  </div>
</div>

```{r Imagen octocat 2, fig.align = 'center', out.width = "150", eval = FALSE, echo = FALSE, message = FALSE}

knitr::include_graphics('Imagenes/octocat_5.png')
```

<!--Una distribución contiene información sobre probabilidades asociadas con los puntos. Por ejemplo, las distribuciones revelan qué valores son típicos, cuáles son raros y cuáles son aparentemente imposibles. Una distribución también revela la "mejor suposición" para predecir valores futuros, así como la certeza o incertidumbre de esa suposición.-->

</div>

</div>

---

<section style="text-align: center;"><h2><p class="text-info">Transformación de las variables</p></h2></section>

<div class = "row">

<div class = "col-md-6">

```{r Distribución de los datos de intervalo entre partos 1, echo = FALSE, eval = TRUE, message = FALSE, fig.align = 'center', out.width = '300'}

Est_dist_2_DE <- datos_entrenamiento %>%
  ggplot(aes(x = IEP)) +
  geom_histogram(aes(y = ..density..), bins = 28, fill = 'yellow', colour = 'yellow', alpha = 0.4) +
  geom_density(size = 2.2, colour = 'black') +
  #annotate(geom = 'text', x = 1.5, y = 0.5, label = 'Distribución normal', family = 'gochi', size = 8.8, colour = 'black') +
  theme_bw() +
  labs(x = 'Intervalo entre partos', y = 'Frecuencia', title = 'Datos de entrenamiento') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 20, face = 'bold'),
        axis.title = element_text(size = 22, face = 'bold'),
        plot.title = element_text(size = 22, face = 'bold'))

Est_dist_2_DE
```

```{r Estadisticos de los datos de entrenamiento y de prueba, echo = FALSE, eval = FALSE, message = FALSE}

Est_dist_DE <- datos_entrenamiento %>%
  summarise(Media = round(mean(IEP), digits = 2), Mediana = median(IEP), Sesgo = round(skewness(IEP), digits = 2), Curtosis = round(kurtosis(IEP), digits = 2))

Est_dist_DP <- datos_prueba %>%
  summarise(Media = round(mean(IEP), digits = 2), Mediana = median(IEP), Sesgo = round(skewness(IEP), digits = 2), Curtosis = round(kurtosis(IEP), digits = 2))
```

<table class="table table-hover">
  <thead>
    <tr>
      <th scope="col">Estadístico</th>
      <th scope="col">Entrenamiento</th>
      <th scope="col">Prueba</th>
    </tr>
  </thead>
  <tbody>
    <tr class="table-danger">
      <th scope="row">Media</th>
      <td>379.53</td>
      <td>379.15</td>
    </tr>
    <tr class="table-success">
      <th scope="row">Mediana</th>
      <td>368</td>
      <td>368</td>
    </tr>
    <tr class="table-warning">
      <th scope="row">Sesgo</th>
      <td>1.28</td>
      <td>1.16</td>
    </tr>
    <tr class="table-secondary">
      <th scope="row">Curtosis</th>
      <td>5.74</td>
      <td>4.61</td>
    </tr>
  </tbody>
</table>

</div>

<div class = "col-md-6">

```{r Distribución de los datos de intervalo entre partos 2, echo = FALSE, eval = TRUE, message = FALSE, fig.align = 'center', out.width = '300'}

Est_dist_2_DP <- datos_prueba %>%
  ggplot(aes(x = IEP)) +
  geom_histogram(aes(y = ..density..), bins = 28, fill = 'yellow', colour = 'yellow', alpha = 0.4) +
  geom_density(size = 2.2, colour = 'black') +
  #annotate(geom = 'text', x = 1.5, y = 0.5, label = 'Distribución normal', family = 'gochi', size = 8.8, colour = 'black') +
  theme_bw() +
  labs(x = 'Intervalo entre partos', y = 'Frecuencia', title = 'Datos de prueba') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 20, face = 'bold'),
        axis.title = element_text(size = 22, face = 'bold'),
        plot.title = element_text(size = 22, face = 'bold'))

Est_dist_2_DP
```

<section style="text-align: justify;"><p class="text-primary">Con el histograma se observó que los datos presentaban asimétria hacia la derecha, puesto que la cola de la distribución apuntaba a la derecha. Respecto a las estadísticas descriptivas, el sesgo distinto de 0 indicó falta de simetría de la distribución, mientras que el valor de la curtosis, que cuantifica el peso de las colas en comparación con la distribución normal cuyo valor debería ser igual a 3, indicó falta de normalidad.</p></section>

<!--
Por lo tanto, al observar el histograma con una asimetría positiva, una curtosis por encima de 3 y un sesgo distinto de 0, se concluyó que la distribución de los datos de intervalo entre partos en bovinos Romosinuano corresponde a una distribución sesgada a la derecha.

Se observó mediante el proceso de visualización anterior (diagrama de caja y bigotes) que el número de valores atípicos en el conjunto de datos de intervalo entre partos era alto. También se observó (mediante un histograma) que la distribución de los datos no seguian una distribución normal. Por lo tanto, se concluyó que el método de escalado de variables apropiado a usar era una escala robusta. Este método funciona restando a los datos la mediana y los escala de acuerdo con el rango intercuartil (IQR). Este método es robusto a los valores atípicos. Sin embargo, dado que esta metodología no la encontre dentro de los procesos del tidymodels en el momento que busque y se me dificulto realizar por medio del paquete scikit-learn de Python este mismo procedimiento, lo que hare será una transformación por box-cox y luego usare una escala común como el ejemplo presentado en este articulo: https://www.tidymodels.org/learn/models/parsnip-nnet/.
-->
</div>

</div>

---

<section style="text-align: center;"><h2><p class="text-info">Balanceo de las variables</p></h2></section>

<br>

<section style="text-align: justify;"><p class="text-primary">Las <font color="black"><u>variables desbalanceadas</u></font> consisten de una proporción desproporcionada de observaciones en cada nivel de una variable predictora. Se considera un problema ya que la mayoría de los algoritmos de machine learning funcionan mejor cuando el número de observaciones es similar. Esto se debe a que dichos algoritmos están diseñados para maximizar la precisión y reducir el error.</p></section>



<div class = "row">

<div class = "col-md-6">

<div class="alert alert-dismissible alert-warning">
  Tipo de balanceo over-sampling
</div>

</div>

<div class = "col-md-6">

<div class="alert alert-dismissible alert-danger">
  Tipo de balanceo under-sampling
</div>

</div>

</div>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Se aumenta el número de obervaciones de los niveles con el menor valor hasta llegar al valor del nivel con el mayor número de observaciones:</p></section>

```{r Oversampling, fig.align = 'center', eval = TRUE, echo = FALSE, message = FALSE, fig.showtext = TRUE, out.width = '200'}

data.frame(
  x = c(1.0:3.5), y = c(1.0:3.5)
) %>%
  ggplot(aes(x, y)) +
  geom_blank() +
  theme_bw() +
  annotate(geom = 'rect', xmin = 1.0, xmax = 1.5, ymin = 1.0, ymax = 2.5, colour = 'cyan', fill = 'cyan', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.0, xmax = 2.5, ymin = 1.0, ymax = 1.5, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 3.0, xmax = 3.5, ymin = 1.0, ymax = 3.5, colour = 'black', fill = 'black', alpha = 0.4, size = 1.2) +
  geom_curve(x = 1.25, xend = 1.25, y = 2.6, yend = 3.5, arrow = arrow(length = unit(0.1, 'inch')), size = 2.0, color = 'black', curvature = 0.0) +
  geom_curve(x = 2.25, xend = 2.25, y = 1.6, yend = 3.5, arrow = arrow(length = unit(0.1, 'inch')), size = 2.0, color = 'black', curvature = 0.0) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```


</div>

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Se disminuye el número de obervaciones de los niveles con mayor valor hasta llegar al valor del nivel con el menor número de observaciones:</p></section>

```{r Undersampling, fig.align = 'center', eval = TRUE, echo = FALSE, message = FALSE, fig.showtext = TRUE, out.width = '200'}

data.frame(
  x = c(1.0:3.5), y = c(1.0:3.5)
) %>%
  ggplot(aes(x, y)) +
  geom_blank() +
  theme_bw() +
  annotate(geom = 'rect', xmin = 1.0, xmax = 1.5, ymin = 1.0, ymax = 2.5, colour = 'cyan', fill = 'cyan', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 2.0, xmax = 2.5, ymin = 1.0, ymax = 1.5, colour = 'yellow', fill = 'yellow', alpha = 0.4, size = 1.2) +
  annotate(geom = 'rect', xmin = 3.0, xmax = 3.5, ymin = 1.0, ymax = 3.5, colour = 'black', fill = 'black', alpha = 0.4, size = 1.2) +
  geom_curve(x = 1.25, xend = 1.25, y = 2.4, yend = 1.5, arrow = arrow(length = unit(0.1, 'inch')), size = 2.0, color = 'black', curvature = 0.0) +
  geom_curve(x = 3.25, xend = 3.25, y = 3.4, yend = 1.5, arrow = arrow(length = unit(0.1, 'inch')), size = 2.0, color = 'black', curvature = 0.0) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

</div>

</div>

<!--
Ver en https://www.tidymodels.org/start/case-study/ la parte donde hablan de desequilibrio en la base de datos empleado. Ellos mencionan métodos para combatir este problema mediante el uso del paquete "recipes" (recetas) por medio de upsample o downsample, u otros paquetes más especializados como "themis" (https://tidymodels.github.io/themis/). 

También en https://canal.uned.es/video/5dd24cff5578f275763a9092 en el minuto 9:16 muestran diferentes técnicas de balanceo
-->

---

<section style="text-align: center;"><h2><p class="text-info">Balanceo de las variables</p></h2></section>

```{r Balanceo de variables predictoras, echo = FALSE, eval = TRUE, message = FALSE, fig.align = 'center', out.width = '570'}

balanceo_OP_DE <- datos_entrenamiento %>%
  dplyr::select(IEP, OP) %>%
  group_by(OP) %>%
  summarise(Total = length(OP)) %>%
  ggplot(aes(x = OP, y = Total)) +
  geom_segment(aes(x = OP, xend = OP, y = 0, yend = Total), color = 'gray44', size = 1.4, alpha = 0.4) +
  geom_point(color = 'cyan2', size = 3.4, alpha = 0.4) +
  geom_text(aes(label = Total), na.rm = TRUE, hjust = -0.2, colour = 'black') +
  theme_bw() +
  labs(x = 'Orden de parto', y = 'Número de\n observaciones', title = '') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 8, face = 'bold'),
        axis.title = element_text(size = 10, face = 'bold'),
        plot.title = element_text(size = 10, face = 'bold'))

balanceo_ÉpP_DE <- datos_entrenamiento %>%
  dplyr::select(IEP, ÉpP) %>%
  group_by(ÉpP) %>%
  summarise(Total = length(ÉpP)) %>%
  ggplot(aes(x = ÉpP, y = Total)) +
  geom_segment(aes(x = ÉpP, xend = ÉpP, y = 0, yend = Total), color = 'gray44', size = 1.4, alpha = 0.4) +
  geom_point(color = 'cyan2', size = 3.4, alpha = 0.4) +
  geom_text(aes(label = Total), na.rm = TRUE, hjust = -0.2, colour = 'black') +
  theme_bw() +
  labs(x = 'Edad al primer parto', y = 'Número de\n observaciones', title = '') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 8, face = 'bold'),
        axis.title = element_text(size = 10, face = 'bold'),
        plot.title = element_text(size = 10, face = 'bold'))

balanceo_SC_DE <- datos_entrenamiento %>%
  dplyr::select(IEP, SC) %>%
  group_by(SC) %>%
  summarise(Total = length(SC)) %>%
  ggplot(aes(x = SC, y = Total)) +
  geom_segment(aes(x = SC, xend = SC, y = 0, yend = Total), color = 'gray44', size = 1.4, alpha = 0.4) +
  geom_point(color = 'cyan2', size = 3.4, alpha = 0.4) +
  geom_text(aes(label = Total), na.rm = TRUE, hjust = -0.2, colour = 'black') +
  theme_bw() +
  labs(x = 'Sexo de la cría', y = 'Número de\n observaciones', title = '') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 8, face = 'bold'),
        axis.title = element_text(size = 10, face = 'bold'),
        plot.title = element_text(size = 10, face = 'bold'))

balanceo_AP_DE <- datos_entrenamiento %>%
  dplyr::select(IEP, AP) %>%
  group_by(AP) %>%
  summarise(Total = length(AP)) %>%
  ggplot(aes(x = AP, y = Total)) +
  geom_segment(aes(x = AP, xend = AP, y = 0, yend = Total), color = 'gray44', size = 1.4, alpha = 0.4) +
  geom_point(color = 'cyan2', size = 3.4, alpha = 0.4) +
  geom_text(aes(label = Total), na.rm = TRUE, hjust = -0.2, colour = 'black') +
  theme_bw() +
  labs(x = 'Año de parto', y = 'Número de observaciones', title = 'Datos de entrenamiento') +
  theme(legend.position = 'none',
        axis.text.y = element_text(size = 5, face = 'bold'),
        axis.text.x = element_text(size = 10, face = 'bold'),
        axis.title = element_text(size = 12, face = 'bold'),
        plot.title = element_text(size = 12, face = 'bold')) +
  coord_flip()

(balanceo_AP_DE) | (balanceo_OP_DE / balanceo_ÉpP_DE / balanceo_SC_DE)
```

---

<section style="text-align: center;"><h2><p class="text-info">Ajuste inicial de un modelo básico de regresión</p></h2></section>

<br>

```{r, fig.align = 'center', out.width = '670', eval = TRUE, echo = FALSE, message = FALSE}

knitr::include_graphics('Imagenes/paquete_recipes.png')
```

---

<section style="text-align: center;"><h2><p class="text-info">Ajuste inicial de un modelo básico de regresión</p></h2></section>

<br>

```{r Ajuste del modelo básico 1 usando el paquete tidymodels, echo = FALSE, eval = FALSE, message = FALSE}

# Se especifica o construye el modelo básico de regresión con el uso del paquete parsnip (en base a https://www.tidymodels.org/start/models/) ----

Reg_bas_mod <- linear_reg(mixture = 1) %>% # Se especifica aqui la forma funcional (o el tipo) del modelo a ajustar usando la función linear_reg() del paquete parsnip. En este caso corresponde a modelo de regresión lineal. Se establece también con "mixture = 1" que no se tendran en cuenta predictores irrelevantes y se elegirá un modelo más simple.
  set_engine('lm') # Aquí se establece el método para ajustar o entrenar el modelo anterior usando "engine" (o el motor en español). En este caso, mínimos cuadrados ordinarios (lm).

# Uso de recipe() del paquete tidymodels para indicar como será el preprocesamiento de los datos (en base a https://www.tidymodels.org/start/recipes/ y https://www.tidymodels.org/start/case-study/) ----

Reg_bas_rec <- recipe(IEP ~ ., data = datos_entrenamiento) %>% # Aquí, la variable al lado izquierdo de "~" se considera la variabe respuesta, y las del lado derecho las variables predictoras. Se indico con "." todas las demás variables además de "IEP" como variables predictoras, y en "data" el conjunto de entrenamiento.
  step_rm(Individuo) %>% # Con step_rm() se eliminan las variables que no se quieren en el modelo, en este caso, la identificación del individuo.
  step_upsample(AP, over_ratio = 1) %>% # Con la función step_upsample() se replica de forma aleatoria y con reemplazo el número de observaciones de los niveles de la variable año de parto (y las otras variables predictoras). "over_ratio = 1", significa que el número de dichas observaciones de las clases minoritarias se muestrean para tener la misma frecuencia que el nivel más frecuente... el valor de 1 de over_ratio es el valor predeterminado. 
  step_upsample(OP, over_ratio = 1) %>%
  step_upsample(ÉpP, over_ratio = 1) %>%
  step_upsample(SC, over_ratio = 1) %>%
  step_dummy(all_nominal()) %>% # Aquí, los caracteres o factores (o variables nominales) se convierten en variables dummy o variables indicadoras.
  step_BoxCox(IEP) %>% # Para tratar los datos de IEP con valores atípicos y distribución con sesgo a la derecha, se transforma esta variable usando las funciones step_BoxCox() y step_normalize(), como en el ejemplo de https://www.tidymodels.org/learn/models/parsnip-nnet/.
  step_normalize(IEP)

#recipe(IEP ~ ., data = datos_entrenamiento) %>% # De esta forma es posible ver como funciona la función step_upsample().
  #step_upsample(AP, over_ratio = 1) %>%
  #prep() %>%
  #juice() %>%
  #ggplot(aes(AP)) +
  #geom_bar()

# Una vez se construyo el modelo y se prepardo la receta, se usa un "model workflow" (flujo de trabajo modelo) para combinar ambos procesos juntos. Esto mediante la función workflow() del paquete tidymodels (en base a https://www.tidymodels.org/start/recipes/) ----

Reg_bas_wflow <- workflow() %>%
  add_model(Reg_bas_mod) %>% # Modelo ajustado anteriormente
  add_recipe(Reg_bas_rec) # Receta anterior
Reg_bas_wflow

# Ahora, se crea un objeto que contiene los objetos anteriores de la receta creada y el modelo ajustado... luego, usando la función() del paquete broom se obtiene un "tibble ordenado" de los coeficientes del modelo (en base a https://www.tidymodels.org/start/recipes/) ----

Reg_bas_fit <- Reg_bas_wflow %>%
  fit(data = datos_entrenamiento)

Reg_bas_fit %>%
  pull_workflow_fit() %>%
  tidy()
```

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Se <font color = "black"><u>construye</font></u> inicialmente el modelo:</p></section>

```{r Construcción del modelo básico de regresión, echo = FALSE, eval = TRUE, message = FALSE}

demo_code('
Reg_bas_mod <- linear_reg(mixture = 1) %>%
  set_engine("lm")
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE)
```

<section style="text-align: justify;"><p class="text-primary">Luego se prepara la <font color = "black"><u>receta</font></u>:</p></section>

```{r Preprocesamiento de los datos usando recetas, echo = FALSE, eval = TRUE, message = FALSE}

demo_code('
Reg_bas_rec <- recipe(IEP ~ ., data = datos_entrenamiento) %>% 
  step_rm(Individuo) %>%
  step_upsample(AP) %>%
  step_upsample(OP) %>%
  step_upsample(ÉpP) %>%
  step_upsample(SC) %>%
  step_dummy(all_nominal()) %>%
  step_BoxCox(IEP) %>%
  step_normalize(IEP)
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE)
```

</div>

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-primary">Luego mediante un <font color = "black"><u>flujo de trabajo modelo</u></font> se combinan los dos pasos anteriores:</p></section>

```{r Flujo de trabajo modelo para combinar el modelo y la receta, echo = FALSE, eval = TRUE, message = FALSE}

demo_code('
Reg_bas_wflow <- workflow() %>%
  add_model(Reg_bas_mod) %>%
  add_recipe(Reg_bas_rec)
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE)
```

<section style="text-align: justify;"><p class="text-primary">Finalmente, se accede a los coeficientes del modelo ajustado de <font color = "black"><u>forma ordenada</u></font>:

```{r Obtención del modelo anteriormente ajustado, echo = FALSE, eval = TRUE, message = FALSE}

demo_code('
Reg_bas_fit <- Reg_bas_wflow %>%
  fit(data = datos_entrenamiento)

Resultado_reg_bas <- Reg_bas_fit %>%
  pull_workflow_fit() %>%
  tidy()
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE)
```

</div>

</div>

```{r Ajuste del modelo básico 2 usando el paquete tidymodels, echo = FALSE, eval = FALSE, message = FALSE}

# ----

Reg_bas_mod <- linear_reg(mixture = 1) %>%
  set_engine('lm')

# ----

Reg_bas_rec_2 <- recipe(IEP ~ ., data = datos_entrenamiento) %>%
  step_rm(Individuo) %>%
  step_downsample(AP, under_ratio = 1) %>%  # Aquí con la función step_downsample() contario a la función anterior step_upsample() el número de observaciones de las clases mayoritarias se muestrean para tener la misma frecuencia que el nivel menos frecuente.
  step_downsample(OP, under_ratio = 1) %>%
  step_downsample(ÉpP, under_ratio = 1) %>%
  step_downsample(SC, under_ratio = 1) %>%
  step_dummy(all_nominal()) %>%
  step_BoxCox(IEP) %>%
  step_normalize(IEP)

#recipe(IEP ~ ., data = datos_entrenamiento) %>% # De esta forma es posible ver como funciona la función step_downsample().
  #step_downsample(AP, under_ratio = 1) %>%
  #prep() %>%
  #juice() %>%
  #ggplot(aes(AP)) +
  #geom_bar()

# ----

Reg_bas_wflow_2 <- workflow() %>%
  add_model(Reg_bas_mod) %>%
  add_recipe(Reg_bas_rec_2)
Reg_bas_wflow_2

# ----

Reg_bas_fit_2 <- Reg_bas_wflow_2 %>% # Da un error creeria yo porque por medio de la función step_downsample() se lleva a un número de observaciones de cada nivel tal que no sea posible ajustar el modelo.
  fit(data = datos_entrenamiento)

Reg_bas_fit_2 %>%
  pull_workflow_fit() %>%
  tidy()
```

---

<section style="text-align: center;"><h2><p class="text-info">Ajuste de un modelo básico de regresión</p></h2></section>

<br>

```{r Resultado del modelo de regresión básico, eval = TRUE, echo = FALSE, message = FALSE}

Resultado_reg_bas
```

---

<section style="text-align: center;"><h2><p class="text-info">Ajuste de un modelo de regresión mixto</p></h2></section>

<!--
En estas paginas comparten paso a paso el uso de varios paquetes del paquete tidymodels para ajustar un modelo de regresión logistica (entonces creo que se podria hacer lo mismo para modelos mixtos):
- https://www.tidymodels.org/start/recipes/
- https://www.tidymodels.org/start/case-study/... se especificaria que es un modelo de regresión logistica usando la función logistic_reg() y "glmnet" dentro de la función set_engine()... aquí también hablan de la función step_rm() para elinar aquellas variables que no se usaran en el modelo, step_dummy() para convertir caracteres o factores en variables dummy y step_normalize() que centra y escala variables numéricas... también la forma de crear el modelo, la receta y agrupar ambos en un workflow()... también comparan el modelo de regresión logística con uno basado en arboles de decisión (bosque aleatorio).

En esta pagina comparten paso a paso una forma de medir, basado en estadísticas de remuestreo, qué tan bien el modelo ajustado mediante los pasos anteriores predice nuevos datos:
- https://www.tidymodels.org/start/resampling/... también dan un ejemplo de arboles de decisión y bosques aleatorios.
-->
