---
title: " "
subtitle: " "
author: " "
date: " "
output:
  revealjs::revealjs_presentation:
    css: estilo.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE,
                      message = FALSE,
                      warning = FALSE)

library(dplyr)
library(ggplot2)
library(ggforce)
library(showtext) # Link donde estan las fuentes Google (http://www.google.com/fonts)
font_add_google('Gochi Hand', 'gochi')
showtext.auto()
```

---

<h1><p class="text-primary">Modelo de efectos mixtos, machine learning y deep learning</p></h1>
<h2><p class="text-primary"><strong>Resumen de trabajos de interés</strong></p></h2>

<div class = "row">

<div class = "col-md-5">

![](Imagenes/ML_1.png)

</div>

<div class = "col-md-2">

</div>

<div class = "col-md-5">

![](Imagenes/ML_2.png)

</div>

</div>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-secondary">La <font color="black"><u>inteligencia artificial</u></font> es el nombre de todo un campo de conocimiento, similar a la biología o la química. El <font color="black"><u>machine learning</u></font> es una rama de la inteligencia artificial que viene ganando popularidad.</p></section>

</div>

<div class = "col-md-1">

</div>

<div class = "col-md-5">

```{r, echo = FALSE, eval = TRUE, fig.showtext = TRUE, fig.align = "center", fig.cap = ""}

data.frame(
  x = c(1:8), y = c(1:8)
) %>%
  ggplot(aes(x, y)) +
  geom_blank() +
  annotate(geom = 'rect', xmin = 1.5, xmax = 7.5, ymin = 1.5, ymax = 7.5, colour = 'yellow', fill = 'yellow', alpha = 0.4) +
  annotate(geom = 'text', x = 3.2, y = 7.0, label = 'Inteligencia artificial', family = 'gochi', size = 17.4, colour = 'black') +
  annotate(geom = 'rect', xmin = 2.5, xmax = 7.0, ymin = 2.0, ymax = 6.5, colour = 'cyan', fill = 'cyan', alpha = 0.4) +
  annotate(geom = 'text', x = 4.0, y = 6.0, label = 'Machine learning', family = 'gochi', size = 17.4, colour = 'black') +
  annotate(geom = 'rect', xmin = 3.5, xmax = 6.5, ymin = 2.5, ymax = 5.5, colour = 'red', fill = 'red', alpha = 0.4) +
  annotate(geom = 'text', x = 4.8, y = 5.0, label = 'Redes neuronales', family = 'gochi', size = 17.4, colour = 'black') +
  annotate(geom = 'rect', xmin = 4.5, xmax = 6.0, ymin = 3.0, ymax = 4.5, colour = 'black', fill = 'black', alpha = 0.4) +
  annotate(geom = 'text', x = 5.6, y = 3.5, label = 'Deep learning', family = 'gochi', size = 17.4, colour = 'black') +
  theme_void() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

</div>

</div>

<section style="text-align: justify;"><p class="text-secondary">Las <font color="black"><u>redes neuronales</font></u> son uno de los tipos de machine learning. Uno popular, pero hay otros también muy buenos. El <font color="black"><u>deep learning</u></font> es un método moderno de construcción, capacitación y uso de redes neuronales. Básicamente, es una nueva arquitectura.</p></section>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<div class = "row">

<div class = "col-md-5">

<section style="text-align: justify;"><p class="text-secondary"><font color="black"><u>Nunca</u></font> hay una única forma de resolver un problema en el mundo del machine learning. Siempre hay varios algoritmos que se ajustan, y se debe elegir el mejor.</p></section>

```{r Imagen, fig.align = 'center', eval = FALSE, echo = FALSE, message = FALSE, out.width = "140"}

knitr::include_graphics('Imagenes/mapa_mundo_ML.jpg')
```

</div>

<div class = "col-md-1">

</div>

<div class = "col-md-6">

<!-- Hoy en día hay cuatro tipos principales de machine learning: -->

```{r, echo = FALSE, eval = TRUE, fig.showtext = TRUE, fig.align = "center", fig.cap = ""}

data.frame(
  x = c(1:8), y = c(1:8)
) %>%
  ggplot(aes(x, y)) +
  geom_blank() +
  annotate(geom = 'text', x = 4.4, y = 7.0, label = 'Los principales tipos de machine learning', family = 'gochi', size = 20.4, colour = 'black') +
  annotate(geom = 'text', x = 2.4, y = 6.2, label = 'datos simples', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 2.4, y = 5.8, label = 'características claras', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'segment', x = 2.4, xend = 2.3, y = 6.8, yend = 6.4, colour = 'black', size = 1.2) +
  geom_curve(x = 2.2, xend = 2.1, y = 5.6, yend = 4.8, arrow = arrow(length = unit(0.1, 'inch')), size = 1.2, color = 'black', curvature = 0.0) +
  annotate(geom = 'text', x = 2.4, y = 4.6, label = 'ML clásico', family = 'gochi', size = 20.4, colour = 'black') +
  annotate(geom = 'text', x = 3.4, y = 3.8, label = 'sin datos,', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 3.4, y = 3.4, label = 'pero se tiene', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 3.4, y = 3.0, label = 'un entorno', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 3.4, y = 2.6, label = 'para interactuar', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 3.4, y = 1.4, label = 'Reiforcement learning', family = 'gochi', size = 20.4, colour = 'black') +
  annotate(geom = 'segment', x = 4.2, xend = 3.5, y = 6.8, yend = 4.0, colour = 'black', size = 1.2) +
  geom_curve(x = 3.3, xend = 3.2, y = 2.4, yend = 1.6, arrow = arrow(length = unit(0.1, 'inch')), size = 1.2, color = 'black', curvature = 0.0) +
  annotate(geom = 'text', x = 5.2, y = 6.2, label = 'cuando la', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 5.2, y = 5.8, label = 'calidad es un', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 5.2, y = 5.4, label = 'problema real', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 5.2, y = 4.2, label = 'Ensembles', family = 'gochi', size = 20.4, colour = 'black') +
  annotate(geom = 'segment', x = 4.6, xend = 4.7, y = 6.8, yend = 6.4, colour = 'black', size = 1.2) +
  geom_curve(x = 4.9, xend = 5.0, y = 5.3, yend = 4.4, arrow = arrow(length = unit(0.1, 'inch')), size = 1.2, color = 'black', curvature = 0.0) +
  annotate(geom = 'text', x = 6.4, y = 3.4, label = 'datos complicados', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 6.4, y = 3.0, label = 'características poco claras', family = 'gochi', size = 16.4, colour = 'gray24') +
  annotate(geom = 'text', x = 6.4, y = 2.2, label = 'Redes neuronales', family = 'gochi', size = 20.4, colour = 'black') +
  annotate(geom = 'text', x = 6.4, y = 1.8, label = 'y deep learning', family = 'gochi', size = 20.4, colour = 'black') +
  annotate(geom = 'segment', x = 6.1, xend = 6.7, y = 6.8, yend = 3.6, colour = 'black', size = 1.2) +
  geom_curve(x = 6.9, xend = 7.0, y = 2.8, yend = 2.4, arrow = arrow(length = unit(0.1, 'inch')), size = 1.2, color = 'black', curvature = 0.0) +
  theme_void() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

</div>

</div>

<section style="text-align: justify;"><p class="text-secondary">Las técnicas y métodos de machine learning pueden funcionar con una gran cantidad de datos complejos, de alta dimensión y enormes, y <font color="black"><u>pueden usarse para desarrollar modelos de regresión</u></font> y clasificación.</p></section>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<!--
<section style="text-align: justify;"><p class="text-secondary">El machine learning clásico a menudo se divide en dos categorías: <font color="black"><u>supervisado</u></font> y <font color="black"><u>no supervisado</u></font>.</p></section>
-->

```{r, echo = FALSE, eval = TRUE, fig.showtext = TRUE, fig.align = "center", fig.cap = ""}

data.frame(
  x = c(1:8), y = c(1:8)
) %>%
  ggplot(aes(x, y)) +
  geom_blank() +
  annotate(geom = 'text', x = 4.4, y = 7.0, label = 'Machine learning clásico', family = 'gochi', size = 20.4, colour = 'black') +
  annotate(geom = 'text', x = 2.2, y = 6.2, label = 'los datos son', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'text', x = 2.2, y = 5.8, label = 'precategorizados o', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'text', x = 2.2, y = 5.4, label = 'numéricos', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'segment', x = 4.0, xend = 2.2, y = 6.8, yend = 4.4, colour = 'black', size = 1.2) +
  annotate(geom = 'text', x = 2.0, y = 4.2, label = 'Supervisado', family = 'gochi', size = 20.4, colour = 'black') +
  annotate(geom = 'text', x = 1.4, y = 3.4, label = 'predice una', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'text', x = 1.4, y = 3.0, label = 'categoría', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'segment', x = 2.4, xend = 1.6, y = 4.0, yend = 2.4, colour = 'black', size = 1.2) +
  annotate(geom = 'text', x = 1.6, y = 2.2, label = 'Clasificación', family = 'gochi', size = 16.4, colour = 'black') +
  annotate(geom = 'text', x = 3.6, y = 3.4, label = 'predice un', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'text', x = 3.6, y = 3.0, label = 'número', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'segment', x = 2.6, xend = 3.4, y = 4.0, yend = 2.4, colour = 'black', size = 1.2) +
  annotate(geom = 'text', x = 3.4, y = 2.2, label = 'Regresión', family = 'gochi', size = 16.4, colour = 'black') +
  annotate(geom = 'text', x = 6.4, y = 6.2, label = 'los datos no', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'text', x = 6.4, y = 5.8, label = 'están etiquetados de', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'text', x = 6.4, y = 5.4, label = 'ninguna manera', family = 'gochi', size = 10.4, colour = 'gray24') +
  annotate(geom = 'segment', x = 4.4, xend = 6.2, y = 6.8, yend = 4.4, colour = 'black', size = 1.2) +
  annotate(geom = 'text', x = 6.2, y = 4.2, label = 'No supervisado', family = 'gochi', size = 20.4, colour = 'black') +
  theme_void() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<section style="text-align: justify;"><p class="text-secondary">En el <font color="black"><u>aprendizaje supervisado</u></font>, el modelo simplemente aprende a mapear las características de entrada dadas o la variable predictora $x$ y la variable de salida o respuesta $y$ en los conjuntos de datos de entrenamiento. La muestra de entrenamiento actúa como supervisor en el proceso de aprendizaje.</p>

<p class="text-secondary">En el aprendizaje supervisado, cuando la variable de salida es un valor categórico o discreto, entonces es <font color="black"><u>clasificación</u></font>, pero cuando la variable de salida es un valor continuo, entonces es una <font color="black"><u>regresión.</u></font> [Aquí](https://www.youtube.com/watch?v=LliMpfMtjEo) un video sobre esto.</p></section>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<section style="text-align: justify;"><p class="text-secondary">La fórmula simple para explicar el problema de regresión (<font color="black"><u>en el estudio a desarrollar se esta interesado en el problema de regresión</u></font>) viene dada por la ecuación:</p>

$$y = f(x) + b$$

<p class="text-secondary">El propósito de la regresión es estimar el valor de la variable respuesta $y$ utilizando la función $f(x)$ a partir de conjuntos de datos de entrada dados y su término de errores.</p>

<p class="text-secondary">En la regresión, el modelo aprende de los datos en diversas técnicas para minimizar el sesgo y la varianza hasta que en algún momento la predicción del modelo haya logrado el mejor ajuste.</p>

</section>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<section style="text-align: justify;"><p class="text-secondary">Se pueden usar muchos algoritmos de regresión de machine learning para predecir la salida continua:</p>

<p class="text-warning"><strong><u>Random forest (árboles de decisión)</u></strong></p>



</section>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<section style="text-align: justify;"><p class="text-secondary">Se pueden usar muchos algoritmos de regresión de machine learning para predecir la salida continua:</p>

<p class="text-info"><strong><u>Support vector regression (regresión de vector de soporte)</u></strong></p>



</section>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<section style="text-align: justify;"><p class="text-secondary">El <font color="black"><u>modelo mixto</u></font> es un modelo estadístico que comprende efectos fijos y efectos aleatorios.</p>

<div class = "row">

<div class = "col-md-5">

<p class="text-secondary">Los modelos de efectos mixtos son adecuados para conjuntos de datos que tienen estructura de clúster. La estructura del clúster puede ser longitudinal (imagen a la izquierda) o jerárquica (imagen a la derecha).</p>

<!--
La estructura longitudinal se da cuando la observación se mide múltiples veces dentro de un mismo grupo. En cuanto a la estructura jerárquica, consiste de observaciones que tienen similitudes y se pueden clasificar en un mismo grupo.
-->

</div>

<div class = "col-md-1">

</div>

<div class = "col-md-6">

```{r, echo = FALSE, eval = TRUE, fig.showtext = TRUE, fig.align = "center", fig.cap = ""}

a <- data.frame(
  x = c(0.5, 1.5, 0.5, 2.5, 1.5), 
  y = c(1, 1.5, 2, 1, 2.5),
  grupo = c('A', 'B', 'C', 'D', 'E')
) %>%
  ggplot(aes(x0 = x, y0 = y, r = 0.4, fill = grupo, colour = grupo)) +
  geom_circle(alpha = 0.4, size = 0.8) +
  theme_bw() +
  theme(legend.position = 'none') +
  scale_fill_manual(values = c('black', 'cyan', 'red', 'yellow', 'gray')) +
  scale_colour_manual(values = c('black', 'cyan', 'red', 'yellow', 'gray')) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())

b <- data.frame(
  x = c(0.5, 0.5, 1.5, 1.5, 0.5), 
  y = c(1, 1, 1.5, 1.5, 2.0),
  grupo = c('A', 'B', 'C', 'D', 'E')
) %>%
  ggplot(aes(x0 = x, y0 = y, r = c(0.4, 0.2, 0.5, 0.2, 0.3), fill = grupo, colour = grupo)) +
  geom_circle(alpha = 0.4, size = 0.8) +
  theme_bw() +
  theme(legend.position = 'none') +
  scale_fill_manual(values = c('cyan', 'black', 'yellow', 'red', 'gray')) +
  scale_colour_manual(values = c('cyan', 'black', 'yellow', 'red', 'gray')) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())

gridExtra::grid.arrange(a, b, ncol = 2)
```

</div>

</div>

</section>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<section style="text-align: justify;"><p class="text-secondary">Se ha propuesto un enfoque para manejar el clúster en los datos, el <font color="black"><u>machine learning de efectos mixtos</u></font>.</p>

<br>

```{r, fig.align = 'center', out.width = "400", eval = TRUE, echo = FALSE, message = FALSE}

knitr::include_graphics('Imagenes/asombro.gif')
```

</section>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<section style="text-align: justify;"><p class="text-warning"><strong><u>Random forest</u> de efectos mixtos</strong></p>

</section>

---

<h2><p class="text-primary"><strong>Un pequeño repaso</strong></p></h2>

<section style="text-align: justify;"><p class="text-info"><strong><u>Support vector regression</u> de efectos mixtos</strong></p>

</section>

---

<h3><p class="text-primary"><strong><u>Trabajo:</u> <a href="/Documentos/Trabajo_1.pdf" class="download" title="PDF" target="_blank"><font color="black">compare machine learning methods and linear mixed models with random effects of longitudinal data prediction</font></a></strong></p></h3>

<div class = "row">

<div class = "col-md-6">

<section style="text-align: justify;"><p class="text-secondary"><font color="black"><u>Problema</u></font>: Los autores mencionan que los modelos comunmente usados (en este caso, con datos longitudinales) trabajan bajo supuestos hechos en la distribución de los datos y del modelo... los métodos tradicionales tienen una fuerte dependencia de los supuestos.</p></section>

</div>

<div class = "col-md-1">

</div>

<div class = "col-md-5">

<section style="text-align: justify;"><p class="text-secondary">En comparación con los métodos tradicionales, los métodos de <font color="black"><u>machine learning</u></font> no requieren suposiciones sobre la distribución de los datos, y utilizan la validación cruzada para juzgar la calidad del modelo en su lugar.</p></section>

</div>

</div>
